{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNlAoGp+vWum8zAr6zPluwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drew-walkerr/CDCSodiumNitriteStudy/blob/main/nvdrs_narrative_su_nlp_dw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-52EgUOelyWH",
        "outputId": "073a9d85-bca5-46f8-c748-9718c944cb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.21.1 rapidfuzz-3.1.1\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.22.4)\n",
            "Collecting hdbscan>=0.8.29 (from bertopic)\n",
            "  Downloading hdbscan-0.8.30.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn>=0.5.0 (from bertopic)\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.65.0)\n",
            "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.13.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.35)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.15.2+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (23.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.30-cp310-cp310-linux_x86_64.whl size=3543434 sha256=6890cfd38cf2d16e4151bc74b6af333e875723ef0cf9ff7ef9cd97875e5a0bd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/0d/80/d2146d1c4957154f57f01ce239c1d107e26a001c9bb9c2d47b\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=a297bae3b6ec3c69114c74c77c9f5299405bc8b1f3a551ecac3e061c4224daab\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=13fe120f919a556dbc154386ff255a0759a9d249da8eb640ef9cb7a12506d625\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=ce7f5004b611f84af28adaff3563f2eb6c1b1feb2cb65c6b41170f203c2866ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
            "Successfully installed bertopic-0.15.0 hdbscan-0.8.30 huggingface-hub-0.16.4 pynndescent-0.5.10 safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install Levenshtein\n",
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Google drive setup\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ar6oZ6Kd8n9",
        "outputId": "0ec46763-f61f-4c29-b372-cbf0c89c23e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import Cython\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from collections import defaultdict\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import Levenshtein, re\n",
        "import sys\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "import itertools\n",
        "\n",
        "\n",
        "%cd /content/gdrive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuxsDWyHd7Zc",
        "outputId": "04dd84e0-e4fb-4cc9-8586-0d6fa14436e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            "'11.17.21 Notes.gdoc'\n",
            "'2022 CMN Outcomes.gdoc'\n",
            "'2nd Round Feedback for Arica.gdoc'\n",
            "'About the Streetlight Data Scientist.gdoc'\n",
            "'Abstract Protocol, feasibility, acceptability, adoption, and cost analysis of Streetlight a peer support in-patient palliative care intervention.docx'\n",
            "'Abstract Protocol, feasibility, acceptability, adoption, and cost analysis of Streetlight a peer support in-patient palliative care intervention.gdoc'\n",
            "'Accuracies documentation.gsheet'\n",
            "'ACMT Abstract: identifying stigma, bias, and discrimination among MOUD communities using expanded lexicon.gdoc'\n",
            "'ACMT Poster Presentation.pptx'\n",
            "'Alex Resume DW Edits.gdoc'\n",
            "'AMIA 2023 Conference.gdoc'\n",
            "'Approach Section Detecting Bias.gdoc'\n",
            "'Bag of Words Detecting Bias.gdoc'\n",
            "'BSHE 532 Final Project Group Signup.gsheet'\n",
            "'BSHE 542 Jamboard Dr Crawford Section.gjam'\n",
            "'BSHES 532-1 Group Feedback Signup 4 11 22 .gsheet'\n",
            "'BSHES 532-4 Group Feedback Signup 4 11 22 .gsheet'\n",
            "'C4C Analyses and Blurb 2.docx'\n",
            "'C4C Analyses and Blurb 2.gdoc'\n",
            "'CDC Sodium Nitrite Location Classification Doc.gdoc'\n",
            "'CDC Sodium Nitrite Locations Annotation Ontology.gdoc'\n",
            "'Cherokee Nation Dispensary Prices and Promotion Qual Paper .gsheet'\n",
            "'Cherokee Nation Medical Cannabis Qual Storefront Coding Ontology.gdoc'\n",
            "'CMN 2020 Bridge-Pilot Support Template.docx'\n",
            "'CMN 2020 Bridge-Pilot Support Template.gdoc'\n",
            "'CMN 2023 June SL Research Report.gdoc'\n",
            "'Coding Ontology for MOUD Subreddit stigma and bias lexicon.gdoc'\n",
            " \u001b[0m\u001b[01;34mcolab_notebooks\u001b[0m/\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " \u001b[01;34mColabNotebooks\u001b[0m/\n",
            "'CommonlyWell Analyses Notes.gdoc'\n",
            "'CommonlyWell Indiana DMHA Report.gdoc'\n",
            "'Comps Methods Practice.gslides'\n",
            "'Comps Methods Retake.gdoc'\n",
            "'Comps Topic Defense.gdoc'\n",
            "'Comps Topic Paper Oral Defense.gslides'\n",
            "'Concept Model Adult Recreational Leagues PA and Social Capital.gslides'\n",
            "'Concept Models 11.12.20.gslides'\n",
            "'Copy of BSHES 532-1 Group Presentations 4 25 22.gsheet'\n",
            "'Copy of Specific Aims Drew Walker.gdoc'\n",
            "'COVID-19 Mask Wearing Causal Loop.gslides'\n",
            "'C. PRELIMINARY STUDIES-Ana.docx.gdoc'\n",
            "'Curriculum EDI BSHES 721 Theory Syllabus FINAL 2020.docx'\n",
            "'d8 twitter team codebook manuscript.gdoc'\n",
            "'Data collection.gdoc'\n",
            "'Delta 8 Author Disclosures.gdoc'\n",
            "'delta8 twitter nlp paper draft.gdoc'\n",
            "'delta8 twitter nlp paper.gdoc'\n",
            "'Delta 8 Twitter Paper Revisions AJDAA Response 3.gdoc'\n",
            " \u001b[01;34mdetecting_bias\u001b[0m/\n",
            "'Detecting Bias Conceptual Model.gdoc'\n",
            "'Detecting bias in provider notes APPROACH.gdoc'\n",
            "'Detecting Provider Bias in Charts NLP Methods.gsheet'\n",
            "'Detecting Provider Bias Lit Review.gsheet'\n",
            "'Discussion Questions on Critical Race Theory.docx'\n",
            " \u001b[01;34mDiss_Detecting_Provider_Bias\u001b[0m/\n",
            "'Dissertation Hrs.gsheet'\n",
            "'Dissertation Paper Aims.gdoc'\n",
            "'Dissertation Proposal Draft Detecting Bias in Clinical Charts of Patients with Chronic Illnesses Drew Walker.gdoc'\n",
            "'Dissertation Proposal Drew Walker.gslides'\n",
            "'Drew Final Paper Texts as Data.gdoc'\n",
            "'Drew Hours.gsheet'\n",
            "'Drew Hours.xlsx'\n",
            "'Drew Streetlight Hours.gsheet'\n",
            "'Drew Walker CV (1).gdoc'\n",
            "'Drew Walker CV.docx'\n",
            "'Drew Walker CV.gdoc'\n",
            "'Drew Walker CV old.gdoc'\n",
            "'Drew Walker IDP - career contacts.gsheet'\n",
            "'Drew Walker Module A Project.docx'\n",
            "'Drew Walker Module A Project.gdoc'\n",
            "\u001b[01;34m'Early Section Drafts'\u001b[0m/\n",
            "'Ethics writing assignment.gdoc'\n",
            "'Final Paper TADA Geopspatial Network .gdoc'\n",
            "'General Discussion Questions for Socio Ecological Model 2020.docx'\n",
            "'Getting started.pdf'\n",
            "'Gold Standard Detecting Bias.gdoc'\n",
            "'Health+ SCD Wrap Up Highlights 2020-11-05.pptx'\n",
            "'Highlights Delta8 Tweets.gdoc'\n",
            "'HLM Article Review.gdoc'\n",
            "'HLM class HW2 table.gdoc'\n",
            "'Homework Major Themes.gslides'\n",
            "' Identifying experiences of bias, stigma, and discrimination among social media communities related to medications for opioid use disorder using an expanded lexicon matching approach.gdoc'\n",
            " IMG_0325.MOV\n",
            " IMG_1789.mov\n",
            "'JAMIA Reviewer Comments.gdoc'\n",
            "'JAMIA SGOT Figures.gdoc'\n",
            "\u001b[01;34m'JAMIA SGOT Submission'\u001b[0m/\n",
            "'JMT Developing a lexicon for stigma, and discrimination in subreddit communities related to opioid use disorder.gdoc'\n",
            "'JPM Quantitative Study Revision Letter.gdoc'\n",
            "'Letter (1).gdoc'\n",
            " Letter.gdoc\n",
            "'Logic Model of Change Template.gdoc'\n",
            "'Manuscript 1.30.23_REV 2 DW (1).gdoc'\n",
            "'Manuscript 1.30.23_REV 2 DW.docx'\n",
            "'Manuscript 1.30.23_REV 2 DW.gdoc'\n",
            "'Manuscript_R&R_12722.docx'\n",
            "'Manuscript_R&R_12722 DW format.gdoc'\n",
            "\u001b[01;34m'Methadone.zip (Unzipped Files)'\u001b[0m/\n",
            "'Methods Comps Exam Section 2.gdoc'\n",
            "'Methods Retake Comps.gdoc'\n",
            "'Module 3 Week 3: Social Networks and Health Outcomes.gslides'\n",
            "'NHIS Adult 2020 Readme.gdoc'\n",
            "'Notes 8.23.21 EDI Meeting.docx'\n",
            " nvdrs_tokenized.csv\n",
            " nvrds_utf.csv\n",
            "'PCI 2020 SGL Presentation Drew Walker.pptx'\n",
            "'Physical Activity Exercise.gform'\n",
            "'Practice Comps Methods Retake.gdoc'\n",
            "'PRECEDE Analysis.gslides'\n",
            "'Primary Data Collection DPC Waiver.gdoc'\n",
            "'Proposal Class Detecting Bias in Clinical Charts of Patients with Chronic Illnesses Drew Walker.gdoc'\n",
            "'Qualitative SL Outcomes Study.gdoc'\n",
            "'QualWorks Description Activity.gdoc'\n",
            " QuantHomework2FINAL.pages\n",
            "'Quantitative SL Outcomes Study.gdoc'\n",
            "'Quotes in SL Outcomes study .gdoc'\n",
            "'Rental Application - Isabel Walker.gdoc'\n",
            "'Rental Application - Isabel Walker.pdf'\n",
            "'Response to Reviewers JPM.gdoc'\n",
            "'Response to Reviewers JPM Resubmit.gdoc'\n",
            "'Resubmit Figure Legends.gdoc'\n",
            "'Resubmit Response JPM 3 .gdoc'\n",
            "'Resubmit Supplemental Program Utility.gdoc'\n",
            "'Reviewer #1: This article is on an important topic for the MCH audience.gdoc'\n",
            "'Revised delta8 twitter nlp paper draft .gdoc'\n",
            "'Revisions JPM Quant SL Outcomes.gdoc'\n",
            "'Rossheim alcpop plan (1).gdoc'\n",
            "'Rossheim alcpop plan.gdoc'\n",
            " \u001b[01;36mSarker_595\u001b[0m@\n",
            "'Scare Quotes in Medical Charts Ontology (1).gdoc'\n",
            "'Scare Quotes in Medical Charts Ontology.gdoc'\n",
            "'SCData Conversation Tree.gsheet'\n",
            "'SCT Group Activity SFH.docx'\n",
            "'SGL Evaluation Manuscript 1 Draft - Drew and Emily Review.docx'\n",
            "'SGOT Analysis DIscussion.gslides'\n",
            "'SGOT Event Tracking REDCap Plan.gdoc'\n",
            "'SGOT Pediatrics Grand Rounds Presentation.gslides'\n",
            "'SickleStrong Network Intervention Slides SCData2020 Healthathon.gslides'\n",
            "'SickleStrong Network Powerpoint.gslides'\n",
            "'Significance and Innovation Draft Drew Walker_hc.docx'\n",
            "'Significance Section Detecting Provider Bias in Clinical Notes Drew Walker.gdoc'\n",
            "'SL Outcomes Paper TIDieR checklist.gdoc'\n",
            "'SL Outcomes Study.gdoc'\n",
            "'SL Patient Outcomes Author Sheet.gsheet'\n",
            "'SL Pediatric Chair Presentation 2022.gslides'\n",
            "'SL Research Designs Presentation 2023.gslides'\n",
            "'SL SNA Tables and figures.gdoc'\n",
            "'Specific Aims Drew Walker.gdoc'\n",
            " \u001b[01;36mStreetlight\u001b[0m@\n",
            "'Streetlight Clinical Decision Support Tool Census Feature.gdoc'\n",
            "'Streetlight CMN Grant 2023 Due Feb 10.gdoc'\n",
            "'Streetlight Content Analysis Codebook.gdoc'\n",
            "'Streetlight Data Scientist Goals Projects.gslides'\n",
            "'Streetlight feasibility study IRB.gdoc'\n",
            "'Streetlight Gaming and Online Team Event Analysis.gdoc'\n",
            "'Streetlight NIH R21 Study Design.gdoc'\n",
            "'Streetlight Pediatric Gaming and Technology Symposium 2023 Submission Form.gdoc'\n",
            "'Streetlight Pediatric Gaming Symposium Abstract.gslides'\n",
            "'Streetlight Research Coordinator Position.gdoc'\n",
            "'Streetlight Studies.gdoc'\n",
            " substance_nvdrs_regex_results.csv\n",
            "'TADA Assignment 2 Model Accuracy.gsheet'\n",
            "'TADA Assignment 2: Opioid Twitter Pharmacovigilance.gdoc'\n",
            "'Tada Assignment 3.gdoc'\n",
            "'TADA Research Dissertation Updates.gslides'\n",
            "'TANF Conditionality and material hardship, maternal mental health, and parental aggravation.gdoc'\n",
            "'TANF Conditionality and MH Outcomes SSR.gdoc'\n",
            "'TANF Maternal and Child Health RnR Letter.gdoc'\n",
            "'TANF Paper revise 1.docx'\n",
            "'TANF Reviewer Letter.gdoc'\n",
            "'Teaching reflection.gdoc'\n",
            "'Theories Discussion Assignment for 11.19.20.gdoc'\n",
            "'Theory Comps Exam Section 1.gdoc'\n",
            "'To-do list.gsheet'\n",
            "'Topic Comps Exam Section 3.gdoc'\n",
            " top_words_d8_sample_tweets_group_coding.gsheet\n",
            " top_words_d8_sample_tweets.gsheet\n",
            "'Tracing the flow of policy ideas discussant guide.gdoc'\n",
            " Untitled0.ipynb\n",
            "'Untitled document.gdoc'\n",
            "'Untitled drawing.gdraw'\n",
            "'Untitled presentation.gslides'\n",
            " WalkerCoverLetter1.docx\n",
            " WalkerText.gdoc\n",
            "'Walker Workout Tracker .gform'\n",
            "'Walker Workout Tracker  (Responses).gsheet'\n",
            "'Week 13 Discussant Notes: Text Classification and Evaluation.gdoc'\n",
            "'Week 7 Readings Converting text to numbers, dictionary lexicons, regex.gdoc'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying Substance Use\n",
        "\n",
        "* Check data dictionary\n",
        "* Substance use terms list, Abeed paper\n",
        "\n",
        "\n",
        "# OPIOIDS\n",
        "\n",
        "## Prescription Opioids\n",
        "\n",
        "word_list = words.split()\n",
        "\n",
        "\n",
        "prescription_opioids = [\"hydrocodone    hyrdrocodone hydrocodiene hydro_codone hydrocodene hydrocordone hydorcodone hydrocodeine hidrocodone hyrocodone hydrocone hydrodone hyrdocodone hydrcodone hydrocodones hydrocordisone hydocodone hydrocode hydrocodons hydracodone hydrocodone hydrocodin hydrocodine hydrocodon hydrocondone hydrocodne hydrocdone hydros 357s lortab    lortabs lorcet lorcets lortab norco\n",
        "vicodin  vicoden vicadin viodin vicodin vicodines vicodan vicodien viccodin vocodin vicondin vicoding vicodins vicodon vicidin vidodin vikodin viacodin vicodine vicdin vicotin\n",
        "percocet    perkocet percocete percacet pecocet percocette perocets percoets percoet percot perocet percoset percocets percocett pecocets percocoet percocit percet percoct percocet10 percicet percocetes percecet percocet\n",
        "oxycodone   oxocodone oxycodene oxycondone oycodone oxyxodone oxycodones oxicodone oxy_codone oxycodone oxycodine roxycodone ocycodone oxycodons oxcodone oycondone oxycodon oyxcodone oxcycodone oxycodne  oxy oxys roxy roxies roxicodone OC OP percs M30 M30s dilaudid hydromorphone oxymorphone\n",
        "oxycontin   ocycontin oxcontin oxcotin oxcycontin oxycotine oxycontin roxycontin oycotin oxyconton oxycontine oxycotins oxycontin oxycintin oxy_contin oxicontin oxycontins oxycottin oycontin\n",
        "morphine   morphin morfin morphs\n",
        "tramadol   tramadol trmadol tramdol tramadol\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Illicit Opioids\n",
        "fentanyl     fentinyl fentenyl fenanyl fentanly fentnyal fentanol fental fetanyl fentayl fentanayl fentanyl fentyl fentanal fetnyl fentynyl fentnayl fentanl fentyanl fentonyl fentanyal fentany fentnyl fent fents\n",
        "carfentanil    carfentanyl carfentanyl carfent\n",
        "heroin heroin herroin herioin heroins\n",
        "\n",
        "\n",
        "## Medications for Opioid Use Disorder (MOUD)\n",
        "suboxone   suboxine subuxone suboxne suboxone saboxone seboxone subxone suboxene suboxones soboxone suboxon subs subutex zubsolv bunavail probuphine\n",
        "sublocade  sublocade\n",
        "methadone  methodone methadon methadrone methadose methadones methadone mathadone methedone metadone mehtadone methdone\n",
        "blue_methadone blue_methadone\n",
        "buprenorphine  bupenorphine burprenorphine bupronorphine buprenophine bupernorphine buprenorphin buprenorphine bup bupe bupes\n",
        "naltrexone naltrexone naltraxone natrexone naltrexon naltroxone vivitrol vivitrol\n",
        "\n",
        "## Opioid Reversal Agents\n",
        "naloxone naloxone nalaxone\n",
        "narcan narcan evzio\n",
        "\n",
        "\n",
        "## STIMULANTS\n",
        "\n",
        "speedball   speedballin speedballing speedballs speedball\n",
        "methamphetamine    methamphetamines meth methl meths methi methy crystal_meth crystalmeth crystal ice speed crank crystal_meth crystalmeth meth methl meths meth methy methamphetamine\n",
        "lisdexamfetamine   lisdexamfetamine dexamfetamine lisdexamphetamine\n",
        "ritalin    ritialin ritallin ritaline ritlian ritalan ritatlin ritlin riain retalin ritalins ridalin rittalin rittlin ritalyn rialin ritilin ritalin\n",
        "vyvanse    vyvans vvyvanse vyvanses vyvanes vyavanse vyvanse17 vyvense vyvannse vyvance vyvanse vanse vyvanss vivanse vyvanze vyvnase vyvase vyvan vyvansse vyvanase vyanese vyvanse” vyvanese vynanse vyanse vvyanse\n",
        "dextroamphetamine  dextroamphetamines dextroamphetamine levoamphetamine dexamphetamines dextromethamphetamine dexamphetamine\n",
        "levoamphetamine    dexamphetamine dextroamphetamine levoamphetamine levomethamphetamine\n",
        "dexedrine  dexerdrine dexodrine dexetrine dexidrine dexadrine dexedrine\n",
        "amphetamine    amphetamine amphetimines amphetemine amphetimine amphetaminesalt amphetemines anphetamine amphetamines amphetamine amfetamine\n",
        "biphetamine    biphetamine\n",
        "adderall    adderall addrerall sadderall adderell addrall adderals addera adderall adderoll addorall addarall adderrall dadderall aderal adderalll adderallll adderal badderall smadderall addreall adderallxr madderall aderall aderrall adderral adderally adderalls seadderall\n",
        "goofball   goofballs goofball goof\n",
        "\n",
        "*Note: Cocaine was excluded from our analyses due to challenges associated with accurately identifying mentions of the drug\n",
        "\n",
        "## Xylazine?\n",
        "\n",
        "xylazine, tranq\n"
      ],
      "metadata": {
        "id": "kur93452zqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rx opioids\n",
        "prescription_opioids = \"hydrocodone    hyrdrocodone hydrocodiene hydro_codone hydrocodene hydrocordone hydorcodone hydrocodeine hidrocodone hyrocodone hydrocone hydrodone hyrdocodone hydrcodone hydrocodones hydrocordisone hydocodone hydrocode hydrocodons hydracodone hydrocodone hydrocodin hydrocodine hydrocodon hydrocondone hydrocodne hydrocdone hydros 357s lortab    lortabs lorcet lorcets lortab norco vicodin  vicoden vicadin viodin vicodin vicodines vicodan vicodien viccodin vocodin vicondin vicoding vicodins vicodon vicidin vidodin vikodin viacodin vicodine vicdin vicotin percocet    perkocet percocete percacet pecocet percocette perocets percoets percoet percot perocet percoset percocets percocett pecocets percocoet percocit percet percoct percocet10 percicet percocetes percecet percocet oxycodone   oxocodone oxycodene oxycondone oycodone oxyxodone oxycodones oxicodone oxy_codone oxycodone oxycodine roxycodone ocycodone oxycodons oxcodone oycondone oxycodon oyxcodone oxcycodone oxycodne  oxy oxys roxy roxies roxicodone OC OP percs M30 M30s dilaudid hydromorphone oxymorphone oxycontin   ocycontin oxcontin oxcotin oxcycontin oxycotine oxycontin roxycontin oycotin oxyconton oxycontine oxycotins oxycontin oxycintin oxy_contin oxicontin oxycontins oxycottin oycontin morphine   morphin morfin morphs tramadol   tramadol trmadol tramdol tramadol\"\n",
        "prescription_opioids_list = prescription_opioids.split()\n",
        "#Illicit opioids\n",
        "illicit_opioids = \"fentanyl     fentinyl fentenyl fenanyl fentanly fentnyal fentanol fental fetanyl fentayl fentanayl fentanyl fentyl fentanal fetnyl fentynyl fentnayl fentanl fentyanl fentonyl fentanyal fentany fentnyl fent fents carfentanil    carfentanyl carfentanyl carfent heroin heroin herroin herioin heroins\"\n",
        "illicit_opioids_list = illicit_opioids.split()\n",
        "\n",
        "\n",
        "#moud_opioids\n",
        "moud_opioids = \"suboxone   suboxine subuxone suboxne suboxone saboxone seboxone subxone suboxene suboxones soboxone suboxon subs subutex zubsolv bunavail probuphine sublocade  sublocade methadone  methodone methadon methadrone methadose methadones methadone mathadone methedone metadone mehtadone methdone blue_methadone blue_methadone buprenorphine  bupenorphine burprenorphine bupronorphine buprenophine bupernorphine buprenorphin buprenorphine bup bupe bupes naltrexone naltrexone naltraxone natrexone naltrexon naltroxone vivitrol vivitrol\"\n",
        "moud_opioids_list = moud_opioids.split()\n",
        "\n",
        "#Opioid reversal_agents\n",
        "reversal_agents = \"naloxone naloxone nalaxone narcan narcan evzio\"\n",
        "reversal_agents_list = reversal_agents.split()\n",
        "#stimulants, not including cocaine\n",
        "stimulants = \"speedball   speedballin speedballing speedballs speedball methamphetamine    methamphetamines meth methl meths methi methy crystal_meth crystalmeth crystal ice speed crank crystal_meth crystalmeth meth methl meths meth methy methamphetamine lisdexamfetamine   lisdexamfetamine dexamfetamine lisdexamphetamine ritalin    ritialin ritallin ritaline ritlian ritalan ritatlin ritlin riain retalin ritalins ridalin rittalin rittlin ritalyn rialin ritilin ritalin vyvanse    vyvans vvyvanse vyvanses vyvanes vyavanse vyvanse17 vyvense vyvannse vyvance vyvanse vanse vyvanss vivanse vyvanze vyvnase vyvase vyvan vyvansse vyvanase vyanese vyvanse” vyvanese vynanse vyanse vvyanse dextroamphetamine  dextroamphetamines dextroamphetamine levoamphetamine dexamphetamines dextromethamphetamine dexamphetamine levoamphetamine    dexamphetamine dextroamphetamine levoamphetamine levomethamphetamine dexedrine  dexerdrine dexodrine dexetrine dexidrine dexadrine dexedrine amphetamine    amphetamine amphetimines amphetemine amphetimine amphetaminesalt amphetemines anphetamine amphetamines amphetamine amfetamine biphetamine    biphetamine adderall    adderall addrerall sadderall adderell addrall adderals addera adderall adderoll addorall addarall adderrall dadderall aderal adderalll adderallll adderal badderall smadderall addreall adderallxr madderall aderall aderrall adderral adderally adderalls seadderall goofball   goofballs goofball goof\"\n",
        "stimulants_list = stimulants.split()\n",
        "\n",
        "#xylazine\n",
        "xylazine = \"xylazine tranq\"\n",
        "xylazine_list = xylazine.split()"
      ],
      "metadata": {
        "id": "TEX2MNIf3DQs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in NVDRS data"
      ],
      "metadata": {
        "id": "E_AQykmEc5KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nvdrs_raw = pd.read_csv(\"/content/gdrive/MyDrive/Sarker_595/Sarker_595_nvdrs_2020.csv\", encoding='latin-1')\n",
        "nvdrs_raw.head()\n",
        "docs = nvdrs_raw[\"NarrativeLE\"]\n",
        "\n",
        "# Try to tokenize to sentence\n",
        "# Code from mimic-iii\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViZyKJM_nxaa",
        "outputId": "d9b0d504-eb58-4b4b-82fb-44ad00765117"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-aff904a2a376>:1: DtypeWarning: Columns (23,24,29,42,44,46,54,155,156,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,304,305) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  nvdrs_raw = pd.read_csv(\"/content/gdrive/MyDrive/Sarker_595/Sarker_595_nvdrs_2020.csv\", encoding='latin-1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenizing by sentence"
      ],
      "metadata": {
        "id": "gb1vG0wWc2-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()  # just the language with no model\n",
        "nlp.add_pipe('sentencizer')\n",
        "nvdrs_raw[\"NarrativeLE\"] = nvdrs_raw[\"NarrativeLE\"].astype(str)\n",
        "\n",
        "nvdrs_raw[\"Sentence\"] = nvdrs_raw[\"NarrativeLE\"].apply(lambda x: [sent.text for sent in nlp(x).sents])\n",
        "nvdrs_raw = nvdrs_raw.explode(\"Sentence\", ignore_index=True)\n",
        "nvdrs_raw.rename(columns={\"Unnamed: 0\": \"ROW_ID_new\"}, inplace=True)\n",
        "nvdrs_raw.index.name = \"Sentence ID\"\n",
        "\n",
        "nvdrs_raw['Sentence'].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True)\n",
        "\n",
        "nvdrs_raw.to_csv(\"nvdrs_tokenized.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0dC47bipc11I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nvdrs_tokenized = pd.read_csv(\"nvdrs_tokenized.csv\")\n",
        "\n",
        "nvdrs_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7E4u2eNHpiJR",
        "outputId": "6d4dbe4f-4ee7-43f1-85b1-813e074f5964"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ee4a35384533>:1: DtypeWarning: Columns (22,24,25,28,30,32,42,43,45,46,47,48,54,55,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,295,296,299,300,303,304,305,306,307,308,309,310,313,314,318,319) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  nvdrs_tokenized = pd.read_csv(\"nvdrs_tokenized.csv\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sentence ID  IncidentID  IncidentYear       SiteID  IncidentNumber  \\\n",
              "0                  0           2          2003   New Jersey             245   \n",
              "1                  1           3          2003     Virginia             588   \n",
              "2                  2           3          2003     Virginia             588   \n",
              "3                  3           3          2003     Virginia             588   \n",
              "4                  4           3          2003     Virginia             588   \n",
              "...              ...         ...           ...          ...             ...   \n",
              "2090236      2090236     1083150          2018  Puerto Rico            1042   \n",
              "2090237      2090237     1084662          2018   New Jersey            4517   \n",
              "2090238      2090238     1084739          2019   New Jersey            4193   \n",
              "2090239      2090239     1084881          2020   New Jersey            4091   \n",
              "2090240      2090240     1088102          2020  Puerto Rico             772   \n",
              "\n",
              "                                              NarrativeCME  \\\n",
              "0        V a 25 year old, single white male found by hi...   \n",
              "1        V was found hanging in a closet by her sister....   \n",
              "2        V was found hanging in a closet by her sister....   \n",
              "3        V was found hanging in a closet by her sister....   \n",
              "4        V was found hanging in a closet by her sister....   \n",
              "...                                                    ...   \n",
              "2090236  A 57 year old white Hispanic male (V) died by ...   \n",
              "2090237                                                NaN   \n",
              "2090238                                                NaN   \n",
              "2090239  V (64, white, male) died after being admitted ...   \n",
              "2090240  A 25 year old black Hispanic female (V) died b...   \n",
              "\n",
              "                                               NarrativeLE IncidentCategory_c  \\\n",
              "0                                                      NaN     Single suicide   \n",
              "1        V was the daughter of a SFC at an army base wa...     Single suicide   \n",
              "2        V was the daughter of a SFC at an army base wa...     Single suicide   \n",
              "3        V was the daughter of a SFC at an army base wa...     Single suicide   \n",
              "4        V was the daughter of a SFC at an army base wa...     Single suicide   \n",
              "...                                                    ...                ...   \n",
              "2090236  Record not available. For this incident, there...     Single suicide   \n",
              "2090237                                                NaN     Single suicide   \n",
              "2090238                                                NaN     Single suicide   \n",
              "2090239                                                NaN     Single suicide   \n",
              "2090240                              Record not available.     Single suicide   \n",
              "\n",
              "              HomicideSuicide_c  PersonID  ...  MarijuanaTested  \\\n",
              "0        Not a homicide/suicide         2  ...           Tested   \n",
              "1        Not a homicide/suicide         3  ...       Not tested   \n",
              "2        Not a homicide/suicide         3  ...       Not tested   \n",
              "3        Not a homicide/suicide         3  ...       Not tested   \n",
              "4        Not a homicide/suicide         3  ...       Not tested   \n",
              "...                         ...       ...  ...              ...   \n",
              "2090236  Not a homicide/suicide   1133264  ...       Not tested   \n",
              "2090237  Not a homicide/suicide   1134784  ...              NaN   \n",
              "2090238  Not a homicide/suicide   1134861  ...              NaN   \n",
              "2090239  Not a homicide/suicide   1135003  ...              NaN   \n",
              "2090240  Not a homicide/suicide   1138235  ...           Tested   \n",
              "\n",
              "        MarijuanaResult  MuscleRelaxantTested  MuscleRelaxantResult  \\\n",
              "0           Not present                   NaN                   NaN   \n",
              "1        Not Applicable                   NaN                   NaN   \n",
              "2        Not Applicable                   NaN                   NaN   \n",
              "3        Not Applicable                   NaN                   NaN   \n",
              "4        Not Applicable                   NaN                   NaN   \n",
              "...                 ...                   ...                   ...   \n",
              "2090236  Not Applicable            Not tested        Not Applicable   \n",
              "2090237             NaN                   NaN                   NaN   \n",
              "2090238             NaN                   NaN                   NaN   \n",
              "2090239             NaN                   NaN                   NaN   \n",
              "2090240     Not present            Not tested        Not Applicable   \n",
              "\n",
              "        OpiateTested OpiateResult  AlcoholLevel  \\\n",
              "0             Tested  Not present           NaN   \n",
              "1             Tested  Not present           0.0   \n",
              "2             Tested  Not present           0.0   \n",
              "3             Tested  Not present           0.0   \n",
              "4             Tested  Not present           0.0   \n",
              "...              ...          ...           ...   \n",
              "2090236       Tested  Not present           0.0   \n",
              "2090237          NaN          NaN           NaN   \n",
              "2090238          NaN          NaN           NaN   \n",
              "2090239          NaN          NaN           NaN   \n",
              "2090240       Tested      Present           0.0   \n",
              "\n",
              "                                     BloodAlcoholContent_c  \\\n",
              "0                                                      NaN   \n",
              "1        Below the detection limit of the test (<0.01% ...   \n",
              "2        Below the detection limit of the test (<0.01% ...   \n",
              "3        Below the detection limit of the test (<0.01% ...   \n",
              "4        Below the detection limit of the test (<0.01% ...   \n",
              "...                                                    ...   \n",
              "2090236  Below the detection limit of the test (<0.01% ...   \n",
              "2090237                                                NaN   \n",
              "2090238                                                NaN   \n",
              "2090239                                                NaN   \n",
              "2090240  Below the detection limit of the test (<0.01% ...   \n",
              "\n",
              "         CarbonMonoxideSource  \\\n",
              "0                         NaN   \n",
              "1                         NaN   \n",
              "2                         NaN   \n",
              "3                         NaN   \n",
              "4                         NaN   \n",
              "...                       ...   \n",
              "2090236        Not Applicable   \n",
              "2090237                   NaN   \n",
              "2090238                   NaN   \n",
              "2090239                   NaN   \n",
              "2090240        Not Applicable   \n",
              "\n",
              "                                                  Sentence  \n",
              "0                                                      NaN  \n",
              "1        V was the daughter of a SFC at an army base wa...  \n",
              "2                  Rescue responded and began CPR efforts.  \n",
              "3        V was transported to the ER where she was offi...  \n",
              "4        No information was provided regarding circumst...  \n",
              "...                                                    ...  \n",
              "2090236  For this incident, there were no known circums...  \n",
              "2090237                                                NaN  \n",
              "2090238                                                NaN  \n",
              "2090239                                                NaN  \n",
              "2090240                              Record not available.  \n",
              "\n",
              "[2090241 rows x 321 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2214c311-0e12-4f3d-9928-8c9eef28c626\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence ID</th>\n",
              "      <th>IncidentID</th>\n",
              "      <th>IncidentYear</th>\n",
              "      <th>SiteID</th>\n",
              "      <th>IncidentNumber</th>\n",
              "      <th>NarrativeCME</th>\n",
              "      <th>NarrativeLE</th>\n",
              "      <th>IncidentCategory_c</th>\n",
              "      <th>HomicideSuicide_c</th>\n",
              "      <th>PersonID</th>\n",
              "      <th>...</th>\n",
              "      <th>MarijuanaTested</th>\n",
              "      <th>MarijuanaResult</th>\n",
              "      <th>MuscleRelaxantTested</th>\n",
              "      <th>MuscleRelaxantResult</th>\n",
              "      <th>OpiateTested</th>\n",
              "      <th>OpiateResult</th>\n",
              "      <th>AlcoholLevel</th>\n",
              "      <th>BloodAlcoholContent_c</th>\n",
              "      <th>CarbonMonoxideSource</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2003</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>245</td>\n",
              "      <td>V a 25 year old, single white male found by hi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>588</td>\n",
              "      <td>V was found hanging in a closet by her sister....</td>\n",
              "      <td>V was the daughter of a SFC at an army base wa...</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V was the daughter of a SFC at an army base wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>588</td>\n",
              "      <td>V was found hanging in a closet by her sister....</td>\n",
              "      <td>V was the daughter of a SFC at an army base wa...</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rescue responded and began CPR efforts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>588</td>\n",
              "      <td>V was found hanging in a closet by her sister....</td>\n",
              "      <td>V was the daughter of a SFC at an army base wa...</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V was transported to the ER where she was offi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>588</td>\n",
              "      <td>V was found hanging in a closet by her sister....</td>\n",
              "      <td>V was the daughter of a SFC at an army base wa...</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No information was provided regarding circumst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2090236</th>\n",
              "      <td>2090236</td>\n",
              "      <td>1083150</td>\n",
              "      <td>2018</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>1042</td>\n",
              "      <td>A 57 year old white Hispanic male (V) died by ...</td>\n",
              "      <td>Record not available. For this incident, there...</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>1133264</td>\n",
              "      <td>...</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>For this incident, there were no known circums...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2090237</th>\n",
              "      <td>2090237</td>\n",
              "      <td>1084662</td>\n",
              "      <td>2018</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>4517</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>1134784</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2090238</th>\n",
              "      <td>2090238</td>\n",
              "      <td>1084739</td>\n",
              "      <td>2019</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>4193</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>1134861</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2090239</th>\n",
              "      <td>2090239</td>\n",
              "      <td>1084881</td>\n",
              "      <td>2020</td>\n",
              "      <td>New Jersey</td>\n",
              "      <td>4091</td>\n",
              "      <td>V (64, white, male) died after being admitted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>1135003</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2090240</th>\n",
              "      <td>2090240</td>\n",
              "      <td>1088102</td>\n",
              "      <td>2020</td>\n",
              "      <td>Puerto Rico</td>\n",
              "      <td>772</td>\n",
              "      <td>A 25 year old black Hispanic female (V) died b...</td>\n",
              "      <td>Record not available.</td>\n",
              "      <td>Single suicide</td>\n",
              "      <td>Not a homicide/suicide</td>\n",
              "      <td>1138235</td>\n",
              "      <td>...</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Not present</td>\n",
              "      <td>Not tested</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Tested</td>\n",
              "      <td>Present</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>Record not available.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2090241 rows × 321 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2214c311-0e12-4f3d-9928-8c9eef28c626')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2214c311-0e12-4f3d-9928-8c9eef28c626 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2214c311-0e12-4f3d-9928-8c9eef28c626');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regex searching for substances\n",
        "\n",
        "1. Combining substance lexicons"
      ],
      "metadata": {
        "id": "p_VKEF0Dqcv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pandas dataframe of all the substance use related lists, where each row is a word and the column is the substance category word list\n",
        "\n",
        "illicit_opioids_df = pd.DataFrame(illicit_opioids_list, columns=[\"Term\"])\n",
        "illicit_opioids_df[\"substance_category\"] = \"illicit_opioids\"\n",
        "\n",
        "moud_opioids_df = pd.DataFrame(moud_opioids_list, columns=[\"Term\"])\n",
        "moud_opioids_df[\"substance_category\"] = \"moud_opioids\"\n",
        "\n",
        "prescription_opioids_df = pd.DataFrame(prescription_opioids_list, columns=[\"Term\"])\n",
        "prescription_opioids_df[\"substance_category\"] = \"prescription_opioids\"\n",
        "\n",
        "reversal_agents_df = pd.DataFrame(reversal_agents_list, columns=[\"Term\"])\n",
        "reversal_agents_df[\"substance_category\"] = \"reversal_agents\"\n",
        "\n",
        "stimulants_df = pd.DataFrame(stimulants_list, columns=[\"Term\"])\n",
        "stimulants_df[\"substance_category\"] = \"stimulants\"\n",
        "\n",
        "xylazine_df = pd.DataFrame(xylazine_list, columns=[\"Term\"])\n",
        "xylazine_df[\"substance_category\"] = \"xylazine\"\n",
        "\n",
        "substance_terms_df = pd.concat([illicit_opioids_df, moud_opioids_df, prescription_opioids_df, reversal_agents_df, stimulants_df, xylazine_df])\n",
        "\n",
        "substance_terms_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "A4iqFJg3qnMI",
        "outputId": "3bddca7b-7a8f-4355-b2b5-38653ec5b81f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Term substance_category\n",
              "0     fentanyl    illicit_opioids\n",
              "1     fentinyl    illicit_opioids\n",
              "2     fentenyl    illicit_opioids\n",
              "3      fenanyl    illicit_opioids\n",
              "4     fentanly    illicit_opioids\n",
              "..         ...                ...\n",
              "136  goofballs         stimulants\n",
              "137   goofball         stimulants\n",
              "138       goof         stimulants\n",
              "0     xylazine           xylazine\n",
              "1        tranq           xylazine\n",
              "\n",
              "[374 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0981567-6397-42a0-a38c-e041a35bb583\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Term</th>\n",
              "      <th>substance_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fentanyl</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fentinyl</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fentenyl</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fenanyl</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fentanly</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>goofballs</td>\n",
              "      <td>stimulants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>goofball</td>\n",
              "      <td>stimulants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>goof</td>\n",
              "      <td>stimulants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xylazine</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>374 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0981567-6397-42a0-a38c-e041a35bb583')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0981567-6397-42a0-a38c-e041a35bb583 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0981567-6397-42a0-a38c-e041a35bb583');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Searching through dataset"
      ],
      "metadata": {
        "id": "82fDZgtdtOml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create regex which is each stem word + all similar_words identified in the word embeddings step, which will be used to search the charts\n",
        "def group_and_create_regex(dataframe):\n",
        "    grouped_data = dataframe.groupby('substance_category')['Term'].apply(list).reset_index()\n",
        "    grouped_data['regex'] = grouped_data.apply(lambda row: '|'.join([re.escape(word) for word in row['Term']]), axis=1)\n",
        "    return grouped_data\n",
        "\n",
        "grouped_data = group_and_create_regex(substance_terms_df)\n",
        "grouped_data\n",
        "\n",
        "# Create function that takes regex from each row and searches the charts\n",
        "def identify_matching_strings(nvdrs_tokenized, substance_terms_df):\n",
        "    matching_dataframes = []\n",
        "\n",
        "\n",
        "    for index, row in substance_terms_df.iterrows():\n",
        "        regex = row['regex']\n",
        "        substance_category = row['substance_category']\n",
        "        matches = nvdrs_tokenized.loc[nvdrs_tokenized['Sentence'].str.contains(regex, flags=re.IGNORECASE, na=False)].copy()\n",
        "        matches['regex'] = regex\n",
        "        matches['substance_category'] = substance_category\n",
        "        matching_dataframes.append(matches)\n",
        "\n",
        "    if matching_dataframes:\n",
        "        return pd.concat(matching_dataframes, axis=0)\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "result = identify_matching_strings(nvdrs_tokenized, grouped_data)\n",
        "result.to_csv(\"substance_nvdrs_regex_results.csv\")\n",
        "result\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "0qJ5ScbCeQCa",
        "outputId": "29a98725-9814-42fb-810a-aca03c959b0a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sentence ID  IncidentID  IncidentYear         SiteID  IncidentNumber  \\\n",
              "1510            1510         862          2003         Oregon             190   \n",
              "4176            4176        2401          2003       Maryland            1484   \n",
              "4852            4852        2804          2003       Virginia             872   \n",
              "5177            5177        2954          2004       Colorado             411   \n",
              "9293            9293        4641          2004  Massachusetts             816   \n",
              "...              ...         ...           ...            ...             ...   \n",
              "1967900      1967900      770102          2020         Oregon             873   \n",
              "1974596      1974596      777384          2020       New York            1687   \n",
              "1982020      1982020      779617          2020      Louisiana            1414   \n",
              "2084098      2084098      863988          2019         Hawaii             298   \n",
              "2088280      2088280      922996          2020        Indiana            4184   \n",
              "\n",
              "         ...                              BloodAlcoholContent_c  \\\n",
              "1510     ...  Below the detection limit of the test (<0.01% ...   \n",
              "4176     ...  Below the detection limit of the test (<0.01% ...   \n",
              "4852     ...  Below the detection limit of the test (<0.01% ...   \n",
              "5177     ...  Below the detection limit of the test (<0.01% ...   \n",
              "9293     ...  Below the detection limit of the test (<0.01% ...   \n",
              "...      ...                                                ...   \n",
              "1967900  ...                                                NaN   \n",
              "1974596  ...                                                NaN   \n",
              "1982020  ...                                                NaN   \n",
              "2084098  ...  Below the detection limit of the test (<0.01% ...   \n",
              "2088280  ...                                            Unknown   \n",
              "\n",
              "        CarbonMonoxideSource  \\\n",
              "1510                     NaN   \n",
              "4176                     NaN   \n",
              "4852                     NaN   \n",
              "5177                     NaN   \n",
              "9293                     NaN   \n",
              "...                      ...   \n",
              "1967900                  NaN   \n",
              "1974596                  NaN   \n",
              "1982020                  NaN   \n",
              "2084098       Not Applicable   \n",
              "2088280       Not Applicable   \n",
              "\n",
              "                                                  Sentence  \\\n",
              "1510     50 yr old white female V with a history of pol...   \n",
              "4176                      V had a history of heroin abuse.   \n",
              "4852      P1's familiy also told police that P1 used he...   \n",
              "5177     Was a known heroin user, and death was due to ...   \n",
              "9293      V has a hx of heroin abuse and had become det...   \n",
              "...                                                    ...   \n",
              "1967900   On the day prior to this incident, V's wife r...   \n",
              "1974596  The cause of death is the combined effects of ...   \n",
              "1982020   V was found, lifeless, with self inflicted sl...   \n",
              "2084098  The cause of death is mixed drug toxicity of x...   \n",
              "2088280  She stated that she thought he was taking meth...   \n",
              "\n",
              "                                                     regex  substance_category  \n",
              "1510     fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...     illicit_opioids  \n",
              "4176     fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...     illicit_opioids  \n",
              "4852     fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...     illicit_opioids  \n",
              "5177     fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...     illicit_opioids  \n",
              "9293     fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...     illicit_opioids  \n",
              "...                                                    ...                 ...  \n",
              "1967900                                     xylazine|tranq            xylazine  \n",
              "1974596                                     xylazine|tranq            xylazine  \n",
              "1982020                                     xylazine|tranq            xylazine  \n",
              "2084098                                     xylazine|tranq            xylazine  \n",
              "2088280                                     xylazine|tranq            xylazine  \n",
              "\n",
              "[446944 rows x 323 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3580d90c-8df5-40c8-af5e-a5a8b63046a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence ID</th>\n",
              "      <th>IncidentID</th>\n",
              "      <th>IncidentYear</th>\n",
              "      <th>SiteID</th>\n",
              "      <th>IncidentNumber</th>\n",
              "      <th>...</th>\n",
              "      <th>BloodAlcoholContent_c</th>\n",
              "      <th>CarbonMonoxideSource</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>regex</th>\n",
              "      <th>substance_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>1510</td>\n",
              "      <td>862</td>\n",
              "      <td>2003</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50 yr old white female V with a history of pol...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>4176</td>\n",
              "      <td>2401</td>\n",
              "      <td>2003</td>\n",
              "      <td>Maryland</td>\n",
              "      <td>1484</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V had a history of heroin abuse.</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>4852</td>\n",
              "      <td>2804</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>872</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P1's familiy also told police that P1 used he...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5177</th>\n",
              "      <td>5177</td>\n",
              "      <td>2954</td>\n",
              "      <td>2004</td>\n",
              "      <td>Colorado</td>\n",
              "      <td>411</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Was a known heroin user, and death was due to ...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9293</th>\n",
              "      <td>9293</td>\n",
              "      <td>4641</td>\n",
              "      <td>2004</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>816</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V has a hx of heroin abuse and had become det...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967900</th>\n",
              "      <td>1967900</td>\n",
              "      <td>770102</td>\n",
              "      <td>2020</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>873</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>On the day prior to this incident, V's wife r...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974596</th>\n",
              "      <td>1974596</td>\n",
              "      <td>777384</td>\n",
              "      <td>2020</td>\n",
              "      <td>New York</td>\n",
              "      <td>1687</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The cause of death is the combined effects of ...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982020</th>\n",
              "      <td>1982020</td>\n",
              "      <td>779617</td>\n",
              "      <td>2020</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>1414</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V was found, lifeless, with self inflicted sl...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084098</th>\n",
              "      <td>2084098</td>\n",
              "      <td>863988</td>\n",
              "      <td>2019</td>\n",
              "      <td>Hawaii</td>\n",
              "      <td>298</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>The cause of death is mixed drug toxicity of x...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2088280</th>\n",
              "      <td>2088280</td>\n",
              "      <td>922996</td>\n",
              "      <td>2020</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>4184</td>\n",
              "      <td>...</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>She stated that she thought he was taking meth...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>446944 rows × 323 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3580d90c-8df5-40c8-af5e-a5a8b63046a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3580d90c-8df5-40c8-af5e-a5a8b63046a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3580d90c-8df5-40c8-af5e-a5a8b63046a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Total number of columns (323) exceeds max_columns (20) limiting to first (20) columns.\n",
            "Warning: total number of rows (446944) exceeds max_rows (20000). Limiting to first (20000) rows.\n",
            "Warning: Total number of columns (323) exceeds max_columns (20) limiting to first (20) columns.\n",
            "Warning: total number of rows (446944) exceeds max_rows (20000). Limiting to first (20000) rows.\n",
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in Substance-matched NVDRS regex results"
      ],
      "metadata": {
        "id": "9feMO1UFrxon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "substance_regex_results = pd.read_csv(\"substance_nvdrs_regex_results.csv\")\n",
        "\n",
        "substance_regex_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1OjUr4t_rw4j",
        "outputId": "9b7da683-1709-4254-9af0-2b6154369028"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  Sentence ID  IncidentID  IncidentYear         SiteID  ...  \\\n",
              "0             1510         1510         862          2003         Oregon  ...   \n",
              "1             4176         4176        2401          2003       Maryland  ...   \n",
              "2             4852         4852        2804          2003       Virginia  ...   \n",
              "3             5177         5177        2954          2004       Colorado  ...   \n",
              "4             9293         9293        4641          2004  Massachusetts  ...   \n",
              "...            ...          ...         ...           ...            ...  ...   \n",
              "446939     1967900      1967900      770102          2020         Oregon  ...   \n",
              "446940     1974596      1974596      777384          2020       New York  ...   \n",
              "446941     1982020      1982020      779617          2020      Louisiana  ...   \n",
              "446942     2084098      2084098      863988          2019         Hawaii  ...   \n",
              "446943     2088280      2088280      922996          2020        Indiana  ...   \n",
              "\n",
              "                                    BloodAlcoholContent_c  \\\n",
              "0       Below the detection limit of the test (<0.01% ...   \n",
              "1       Below the detection limit of the test (<0.01% ...   \n",
              "2       Below the detection limit of the test (<0.01% ...   \n",
              "3       Below the detection limit of the test (<0.01% ...   \n",
              "4       Below the detection limit of the test (<0.01% ...   \n",
              "...                                                   ...   \n",
              "446939                                                NaN   \n",
              "446940                                                NaN   \n",
              "446941                                                NaN   \n",
              "446942  Below the detection limit of the test (<0.01% ...   \n",
              "446943                                            Unknown   \n",
              "\n",
              "       CarbonMonoxideSource  \\\n",
              "0                       NaN   \n",
              "1                       NaN   \n",
              "2                       NaN   \n",
              "3                       NaN   \n",
              "4                       NaN   \n",
              "...                     ...   \n",
              "446939                  NaN   \n",
              "446940                  NaN   \n",
              "446941                  NaN   \n",
              "446942       Not Applicable   \n",
              "446943       Not Applicable   \n",
              "\n",
              "                                                 Sentence  \\\n",
              "0       50 yr old white female V with a history of pol...   \n",
              "1                        V had a history of heroin abuse.   \n",
              "2        P1's familiy also told police that P1 used he...   \n",
              "3       Was a known heroin user, and death was due to ...   \n",
              "4        V has a hx of heroin abuse and had become det...   \n",
              "...                                                   ...   \n",
              "446939   On the day prior to this incident, V's wife r...   \n",
              "446940  The cause of death is the combined effects of ...   \n",
              "446941   V was found, lifeless, with self inflicted sl...   \n",
              "446942  The cause of death is mixed drug toxicity of x...   \n",
              "446943  She stated that she thought he was taking meth...   \n",
              "\n",
              "                                                    regex substance_category  \n",
              "0       fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...    illicit_opioids  \n",
              "1       fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...    illicit_opioids  \n",
              "2       fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...    illicit_opioids  \n",
              "3       fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...    illicit_opioids  \n",
              "4       fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...    illicit_opioids  \n",
              "...                                                   ...                ...  \n",
              "446939                                     xylazine|tranq           xylazine  \n",
              "446940                                     xylazine|tranq           xylazine  \n",
              "446941                                     xylazine|tranq           xylazine  \n",
              "446942                                     xylazine|tranq           xylazine  \n",
              "446943                                     xylazine|tranq           xylazine  \n",
              "\n",
              "[446944 rows x 324 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcfa5322-2084-4cfe-9a85-843255220873\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence ID</th>\n",
              "      <th>IncidentID</th>\n",
              "      <th>IncidentYear</th>\n",
              "      <th>SiteID</th>\n",
              "      <th>...</th>\n",
              "      <th>BloodAlcoholContent_c</th>\n",
              "      <th>CarbonMonoxideSource</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>regex</th>\n",
              "      <th>substance_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510</td>\n",
              "      <td>1510</td>\n",
              "      <td>862</td>\n",
              "      <td>2003</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50 yr old white female V with a history of pol...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4176</td>\n",
              "      <td>4176</td>\n",
              "      <td>2401</td>\n",
              "      <td>2003</td>\n",
              "      <td>Maryland</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V had a history of heroin abuse.</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4852</td>\n",
              "      <td>4852</td>\n",
              "      <td>2804</td>\n",
              "      <td>2003</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P1's familiy also told police that P1 used he...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5177</td>\n",
              "      <td>5177</td>\n",
              "      <td>2954</td>\n",
              "      <td>2004</td>\n",
              "      <td>Colorado</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Was a known heroin user, and death was due to ...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9293</td>\n",
              "      <td>9293</td>\n",
              "      <td>4641</td>\n",
              "      <td>2004</td>\n",
              "      <td>Massachusetts</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V has a hx of heroin abuse and had become det...</td>\n",
              "      <td>fentanyl|fentinyl|fentenyl|fenanyl|fentanly|fe...</td>\n",
              "      <td>illicit_opioids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446939</th>\n",
              "      <td>1967900</td>\n",
              "      <td>1967900</td>\n",
              "      <td>770102</td>\n",
              "      <td>2020</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>On the day prior to this incident, V's wife r...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446940</th>\n",
              "      <td>1974596</td>\n",
              "      <td>1974596</td>\n",
              "      <td>777384</td>\n",
              "      <td>2020</td>\n",
              "      <td>New York</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The cause of death is the combined effects of ...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446941</th>\n",
              "      <td>1982020</td>\n",
              "      <td>1982020</td>\n",
              "      <td>779617</td>\n",
              "      <td>2020</td>\n",
              "      <td>Louisiana</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V was found, lifeless, with self inflicted sl...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446942</th>\n",
              "      <td>2084098</td>\n",
              "      <td>2084098</td>\n",
              "      <td>863988</td>\n",
              "      <td>2019</td>\n",
              "      <td>Hawaii</td>\n",
              "      <td>...</td>\n",
              "      <td>Below the detection limit of the test (&lt;0.01% ...</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>The cause of death is mixed drug toxicity of x...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446943</th>\n",
              "      <td>2088280</td>\n",
              "      <td>2088280</td>\n",
              "      <td>922996</td>\n",
              "      <td>2020</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>...</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>She stated that she thought he was taking meth...</td>\n",
              "      <td>xylazine|tranq</td>\n",
              "      <td>xylazine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>446944 rows × 324 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcfa5322-2084-4cfe-9a85-843255220873')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcfa5322-2084-4cfe-9a85-843255220873 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcfa5322-2084-4cfe-9a85-843255220873');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modeling\n",
        "\n",
        "Used on the xylazine dataset, which was only matched with 48 different documents"
      ],
      "metadata": {
        "id": "px5QrQnkw8hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "docs = substance_regex_results[\"Sentence\"][substance_regex_results[\"substance_category\"] == \"xylazine\"].copy()\n",
        "\n",
        "topic_model = BERTopic()\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "topic_model.get_topic_info()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "uxyn_BnmqotY",
        "outputId": "f3363f5c-4b3e-406f-f2ea-187ea5850892"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Topic  Count                         Name  \\\n",
              "0     -1      9             -1_and_the_to_rp   \n",
              "1      0     26  0_and_the_had_tranquilizers   \n",
              "2      1     13     1_of_as_was_tranquilizer   \n",
              "\n",
              "                                      Representation  \\\n",
              "0  [and, the, to, rp, of, about, cause, death, we...   \n",
              "1  [and, the, had, tranquilizers, she, was, her, ...   \n",
              "2  [of, as, was, tranquilizer, found, the, identi...   \n",
              "\n",
              "                                 Representative_Docs  \n",
              "0  [Cause of death was ACUTE POLYDRUG INTOXICATIO...  \n",
              "1  [She reported that the V was not sounding righ...  \n",
              "2  [ 9 tabs of cat tranquilizer (there had origin...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82426a10-a985-4959-a688-6da4bcb001a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>9</td>\n",
              "      <td>-1_and_the_to_rp</td>\n",
              "      <td>[and, the, to, rp, of, about, cause, death, we...</td>\n",
              "      <td>[Cause of death was ACUTE POLYDRUG INTOXICATIO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0_and_the_had_tranquilizers</td>\n",
              "      <td>[and, the, had, tranquilizers, she, was, her, ...</td>\n",
              "      <td>[She reported that the V was not sounding righ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1_of_as_was_tranquilizer</td>\n",
              "      <td>[of, as, was, tranquilizer, found, the, identi...</td>\n",
              "      <td>[ 9 tabs of cat tranquilizer (there had origin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82426a10-a985-4959-a688-6da4bcb001a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82426a10-a985-4959-a688-6da4bcb001a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82426a10-a985-4959-a688-6da4bcb001a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pJudf1MwoGG",
        "outputId": "d2ff1a63-46ce-42c9-cf05-d8aa5986be94"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('and', 0.11693493611871776),\n",
              " ('the', 0.09892077624504446),\n",
              " ('had', 0.08486583749477145),\n",
              " ('tranquilizers', 0.07991811312155295),\n",
              " ('she', 0.07482837845264671),\n",
              " ('was', 0.07413164073997347),\n",
              " ('her', 0.06924861244584472),\n",
              " ('his', 0.0615543221740842),\n",
              " ('tranquilizer', 0.05658976634111859),\n",
              " ('to', 0.05561169550607546)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}